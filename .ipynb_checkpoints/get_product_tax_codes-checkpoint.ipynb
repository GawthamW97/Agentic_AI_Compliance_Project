{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbe627-12be-42f0-9b50-c69cc1d51ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import io\n",
    "\n",
    "# If it's a PDF:\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def download_content(url):\n",
    "    \"\"\"\n",
    "    Download content from the URL. Return tuple (content_bytes, content_type)\n",
    "    \"\"\"\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    content_type = resp.headers.get('Content-Type', '')\n",
    "    return resp.content, content_type\n",
    "\n",
    "def parse_html(content_bytes):\n",
    "    \"\"\"\n",
    "    Parse HTML content to find product descriptions and tax codes.\n",
    "    Adjust selectors depending on the page structure.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(content_bytes, 'html.parser')\n",
    "    results = []\n",
    "    # Example: assume each product is in a <div class=\"product\"> (adjust as needed)\n",
    "    for prod in soup.find_all(class_='product'):\n",
    "        desc = prod.find(class_='description')\n",
    "        tax = prod.find(class_='tax-code')\n",
    "        if desc and tax:\n",
    "            results.append({\n",
    "                'description': desc.get_text(strip=True),\n",
    "                'tax_code': tax.get_text(strip=True)\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def parse_pdf(content_bytes):\n",
    "    \"\"\"\n",
    "    Parse PDF content to find product descriptions and tax codes.\n",
    "    We'll extract all text, then use regex or heuristics to pull out relevant parts.\n",
    "    \"\"\"\n",
    "    text = extract_text(io.BytesIO(content_bytes))\n",
    "    results = []\n",
    "    # Example heuristic: assume tax codes are numeric codes, e.g. digits with optional separators\n",
    "    # And descriptions are lines preceding or following them.\n",
    "    # Adjust regex as per actual document format.\n",
    "    # For example:\n",
    "    #   Product: Widget A\n",
    "    #   Tax Code: 12345\n",
    "    \n",
    "    # Pattern to find lines like \"Tax code: 12345\" (case insensitive)\n",
    "    tax_pattern = re.compile(r'Tax\\s*Code\\D*(\\d+)', re.IGNORECASE)\n",
    "    # Maybe description lines could be like \"Description: ....\"\n",
    "    desc_pattern = re.compile(r'Description\\D*(.+)', re.IGNORECASE)\n",
    "    \n",
    "    # Split text into lines\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    for i, line in enumerate(lines):\n",
    "        m_tax = tax_pattern.search(line)\n",
    "        if m_tax:\n",
    "            tax_code = m_tax.group(1)\n",
    "            # try to find description nearby\n",
    "            desc = None\n",
    "            # check prior lines\n",
    "            if i > 0:\n",
    "                m_desc_prev = desc_pattern.search(lines[i-1])\n",
    "                if m_desc_prev:\n",
    "                    desc = m_desc_prev.group(1)\n",
    "            # or check following lines\n",
    "            if desc is None and i + 1 < len(lines):\n",
    "                m_desc_next = desc_pattern.search(lines[i+1])\n",
    "                if m_desc_next:\n",
    "                    desc = m_desc_next.group(1)\n",
    "            # if still none, maybe the description is a few lines above, fallback\n",
    "            if desc is None:\n",
    "                # just take the line before tax\n",
    "                desc = lines[i-1] if i > 0 else ''\n",
    "            results.append({\n",
    "                'description': desc,\n",
    "                'tax_code': tax_code\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = 'https://publications.europa.eu/resource/cellar/bb24a915-9729-11ef-a130-01aa75ed71a1.0006.03/DOC_1'\n",
    "    content, content_type = download_content(url)\n",
    "    \n",
    "    # decide parser\n",
    "    if 'application/pdf' in content_type or url.lower().endswith('.pdf'):\n",
    "        parsed = parse_pdf(content)\n",
    "    else:\n",
    "        parsed = parse_html(content)\n",
    "    \n",
    "    # Output results\n",
    "    for item in parsed:\n",
    "        print(f\"Description: {item['description']}\")\n",
    "        print(f\"Tax code: {item['tax_code']}\")\n",
    "        print('---')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
